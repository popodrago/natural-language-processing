{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12784980,"sourceType":"datasetVersion","datasetId":8069214},{"sourceId":556733,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":423373,"modelId":440902}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-04T12:39:32.294909Z","iopub.execute_input":"2025-09-04T12:39:32.295385Z","iopub.status.idle":"2025-09-04T12:39:32.667302Z","shell.execute_reply.started":"2025-09-04T12:39:32.295356Z","shell.execute_reply":"2025-09-04T12:39:32.666594Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/new-train-for-math-misunderstanding/new_train.csv\n/kaggle/input/map-charting-student-math-misunderstandings/train_Clean.csv\n/kaggle/input/map-charting-student-math-misunderstandings/submission.csv\n/kaggle/input/map-charting-student-math-misunderstandings/test.csv\n/kaggle/input/distilbert-uncased-fine-tuned/pytorch/default/6/misconception_model/config.json\n/kaggle/input/distilbert-uncased-fine-tuned/pytorch/default/6/misconception_model/tokenizer.json\n/kaggle/input/distilbert-uncased-fine-tuned/pytorch/default/6/misconception_model/tokenizer_config.json\n/kaggle/input/distilbert-uncased-fine-tuned/pytorch/default/6/misconception_model/model.safetensors\n/kaggle/input/distilbert-uncased-fine-tuned/pytorch/default/6/misconception_model/special_tokens_map.json\n/kaggle/input/distilbert-uncased-fine-tuned/pytorch/default/6/misconception_model/vocab.txt\n/kaggle/input/distilbert-uncased-fine-tuned/pytorch/default/6/ternary_model/config.json\n/kaggle/input/distilbert-uncased-fine-tuned/pytorch/default/6/ternary_model/tokenizer.json\n/kaggle/input/distilbert-uncased-fine-tuned/pytorch/default/6/ternary_model/tokenizer_config.json\n/kaggle/input/distilbert-uncased-fine-tuned/pytorch/default/6/ternary_model/model.safetensors\n/kaggle/input/distilbert-uncased-fine-tuned/pytorch/default/6/ternary_model/special_tokens_map.json\n/kaggle/input/distilbert-uncased-fine-tuned/pytorch/default/6/ternary_model/vocab.txt\n/kaggle/input/distilbert-uncased-fine-tuned/pytorch/default/6/binary_model/config.json\n/kaggle/input/distilbert-uncased-fine-tuned/pytorch/default/6/binary_model/tokenizer.json\n/kaggle/input/distilbert-uncased-fine-tuned/pytorch/default/6/binary_model/tokenizer_config.json\n/kaggle/input/distilbert-uncased-fine-tuned/pytorch/default/6/binary_model/model.safetensors\n/kaggle/input/distilbert-uncased-fine-tuned/pytorch/default/6/binary_model/special_tokens_map.json\n/kaggle/input/distilbert-uncased-fine-tuned/pytorch/default/6/binary_model/vocab.txt\n/kaggle/input/distilbert-uncased-fine-tuned/pytorch/default/5/misconception_model/config.json\n/kaggle/input/distilbert-uncased-fine-tuned/pytorch/default/5/misconception_model/tokenizer.json\n/kaggle/input/distilbert-uncased-fine-tuned/pytorch/default/5/misconception_model/tokenizer_config.json\n/kaggle/input/distilbert-uncased-fine-tuned/pytorch/default/5/misconception_model/model.safetensors\n/kaggle/input/distilbert-uncased-fine-tuned/pytorch/default/5/misconception_model/special_tokens_map.json\n/kaggle/input/distilbert-uncased-fine-tuned/pytorch/default/5/misconception_model/vocab.txt\n/kaggle/input/distilbert-uncased-fine-tuned/pytorch/default/5/ternary_model/vocab (1).txt\n/kaggle/input/distilbert-uncased-fine-tuned/pytorch/default/5/ternary_model/config (1).json\n/kaggle/input/distilbert-uncased-fine-tuned/pytorch/default/5/ternary_model/special_tokens_map (1).json\n/kaggle/input/distilbert-uncased-fine-tuned/pytorch/default/5/ternary_model/tokenizer (1).json\n/kaggle/input/distilbert-uncased-fine-tuned/pytorch/default/5/ternary_model/tokenizer_config (1).json\n/kaggle/input/distilbert-uncased-fine-tuned/pytorch/default/5/ternary_model/model (1).safetensors\n/kaggle/input/distilbert-uncased-fine-tuned/pytorch/default/5/binary_model/config.json\n/kaggle/input/distilbert-uncased-fine-tuned/pytorch/default/5/binary_model/tokenizer.json\n/kaggle/input/distilbert-uncased-fine-tuned/pytorch/default/5/binary_model/tokenizer_config.json\n/kaggle/input/distilbert-uncased-fine-tuned/pytorch/default/5/binary_model/model.safetensors\n/kaggle/input/distilbert-uncased-fine-tuned/pytorch/default/5/binary_model/special_tokens_map.json\n/kaggle/input/distilbert-uncased-fine-tuned/pytorch/default/5/binary_model/vocab.txt\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"### READY THIS PLEASE BCZ IT IS HELPFUL TO WORK WITH THIS BASELINE\n\n##### HELLO TEAM!! :)  \n\nI have tried a little to come up with this base line for the map-charting-student-math-misunderstanding competitoin that we are participating in.\n\nThis notebook contain data loading, model loading and fine tuning ( This parts are commented in this notebook), model inference on test dataset and submision file saving.\n\nNOTE: \n\n1. It is possible that you can perform **RUN ALL CELLS** and see what the three models do on the test dataset, but the main target I just shared this notebook is for us to help each other to perform **data cleaning** (e.f removing stopwords) as they are not included in the notebook and perform **better model fine-tuning** as the given models (ternary,binary and misconception) in distilbert-uncased-fine-tuned are fine-tuned on one epoch and with no parameter tuning concerned. Then we will be able to perform well\n\n2. Another thing is to note that the **notebook contains three models** that perform different task with the next model being fed on the results of another, so pay attention on cell running and make **sure that the previous model has a very high accuracy** as the results of one affect the other.\n\n3. **Reading the first comments in each notebook** if available because they are more helpful","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\nimport torch\nfrom datasets import Dataset\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T12:39:32.668129Z","iopub.execute_input":"2025-09-04T12:39:32.668516Z","iopub.status.idle":"2025-09-04T12:39:42.399093Z","shell.execute_reply.started":"2025-09-04T12:39:32.668482Z","shell.execute_reply":"2025-09-04T12:39:42.398443Z"}},"outputs":[{"name":"stderr","text":"2025-09-04 12:39:38.939788: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1756989578.964381    2145 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1756989578.971832    2145 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import random\nimport os\n\ndef set_seed(seed: int = 42):\n    \"\"\"\n    Set seed for reproducibility across Python, NumPy, and PyTorch.\n    Ensures deterministic behavior where possible.\n    \"\"\"\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)  # if using multi-GPU\n\n    # Deterministic settings for PyTorch\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n# Set the seed\nSEED = 42\nset_seed(SEED)\n\n# Optional: confirm\nprint(\"Seed set to:\", SEED)\nprint(\"CUDA available:\", torch.cuda.is_available())\nif torch.cuda.is_available():\n    print(\"Device:\", torch.cuda.current_device(), torch.cuda.get_device_name(0))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T12:39:42.401037Z","iopub.execute_input":"2025-09-04T12:39:42.401512Z","iopub.status.idle":"2025-09-04T12:39:42.409809Z","shell.execute_reply.started":"2025-09-04T12:39:42.401493Z","shell.execute_reply":"2025-09-04T12:39:42.408948Z"}},"outputs":[{"name":"stdout","text":"Seed set to: 42\nCUDA available: True\nDevice: 0 Tesla T4\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"\ntrain = pd.read_csv('/kaggle/input/map-charting-student-math-misunderstandings/train_Clean.csv')\ntrain = pd.DataFrame(train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T12:39:42.410695Z","iopub.execute_input":"2025-09-04T12:39:42.411392Z","iopub.status.idle":"2025-09-04T12:39:42.570188Z","shell.execute_reply.started":"2025-09-04T12:39:42.411371Z","shell.execute_reply":"2025-09-04T12:39:42.569462Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"train.head(2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T12:39:42.570953Z","iopub.execute_input":"2025-09-04T12:39:42.571206Z","iopub.status.idle":"2025-09-04T12:39:42.584131Z","shell.execute_reply.started":"2025-09-04T12:39:42.571185Z","shell.execute_reply":"2025-09-04T12:39:42.583429Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   row_id  QuestionId                                       QuestionText  \\\n0     0.0     31772.0  What fraction of the shape is not shaded? Give...   \n1     1.0     31772.0  What fraction of the shape is not shaded? Give...   \n\n           MC_Answer                                 StudentExplanation  \\\n0  \\( \\frac{1}{3} \\)                  0ne third is equal to tree nineth   \n1  \\( \\frac{1}{3} \\)  1 / 3 because 6 over 9 is 2 thirds and 1 third...   \n\n       Category Misconception Category Misconception  \n0  True_Correct           NaN       True_Correct- NA  \n1  True_Correct           NaN       True_Correct- NA  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>QuestionId</th>\n      <th>QuestionText</th>\n      <th>MC_Answer</th>\n      <th>StudentExplanation</th>\n      <th>Category</th>\n      <th>Misconception</th>\n      <th>Category Misconception</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>31772.0</td>\n      <td>What fraction of the shape is not shaded? Give...</td>\n      <td>\\( \\frac{1}{3} \\)</td>\n      <td>0ne third is equal to tree nineth</td>\n      <td>True_Correct</td>\n      <td>NaN</td>\n      <td>True_Correct- NA</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>31772.0</td>\n      <td>What fraction of the shape is not shaded? Give...</td>\n      <td>\\( \\frac{1}{3} \\)</td>\n      <td>1 / 3 because 6 over 9 is 2 thirds and 1 third...</td>\n      <td>True_Correct</td>\n      <td>NaN</td>\n      <td>True_Correct- NA</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"train['Misconception'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T12:39:42.584881Z","iopub.execute_input":"2025-09-04T12:39:42.585232Z","iopub.status.idle":"2025-09-04T12:39:42.599014Z","shell.execute_reply.started":"2025-09-04T12:39:42.585211Z","shell.execute_reply":"2025-09-04T12:39:42.598303Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"array([nan, 'Incomplete', 'WNB', 'SwapDividend', 'Mult', 'FlipChange',\n       'Irrelevant', 'Wrong_Fraction', 'Additive', 'Not_variable',\n       'Adding_terms', 'Inverse_operation', 'Inversion', 'Duplication',\n       'Wrong_Operation', 'Whole_numbers_larger', 'Longer_is_bigger',\n       'Ignores_zeroes', 'Shorter_is_bigger', 'Wrong_fraction',\n       'Adding_across', 'Denominator-only_change',\n       'Incorrect_equivalent_fraction_addition', 'Division',\n       'Subtraction', 'Unknowable', 'Definition', 'Interior', 'Positive',\n       'Tacking', 'Wrong_term', 'Firstterm', 'Base_rate',\n       'Multiplying_by_4', 'Certainty', 'Scale'], dtype=object)"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# containace of the misconception\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nobject_cols = ['Misconception']\n\nfor col in object_cols:\n    plt.figure(figsize=(8,4))\n    train[col].value_counts().plot(kind=\"bar\")\n    plt.title(f\"Frequency of values in '{col}'\")\n    plt.xlabel(\"Category\")\n    plt.ylabel(\"Count\")\n    plt.xticks(rotation=45, ha=\"right\")\n    plt.tight_layout()\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T12:39:42.599956Z","iopub.execute_input":"2025-09-04T12:39:42.600227Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# we will firstly fine tune a bnary classification model on questionText and  MC_answer \n# to predict weathr it is tre or false\n# then we will train another model on questiontext, MC-answer, and studentExplanation to predict\n# 3 classes misconception, correct, neither (or 0,1,2 then we will map this)\n# Again we train a model for multi classification of the Misconceptions, the model will be fine tuned on\n# questionText, MC_answer, (weather correct, neither or miconception), (weather true or false), studentExplanation\n\n# Finall we will join all the predictions according to the submition format e.g True_Neither- NA\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train.head(2)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/map-charting-student-math-misunderstandings/test.csv')\ntest.head(2)","metadata":{"trusted":true,"execution":{"iopub.status.idle":"2025-09-04T12:39:43.091845Z","shell.execute_reply.started":"2025-09-04T12:39:43.028269Z","shell.execute_reply":"2025-09-04T12:39:43.090799Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"   row_id  QuestionId                                       QuestionText  \\\n0   36696       31772  What fraction of the shape is not shaded? Give...   \n1   36697       31772  What fraction of the shape is not shaded? Give...   \n\n                                      QuestionText.1  \\\n0  What fraction of the shape is not shaded? Give...   \n1  What fraction of the shape is not shaded? Give...   \n\n                                  StudentExplanation  \n0  I think that 1/3 is the answer, as it's the si...  \n1  i think this answer is because 3 triangles are...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>QuestionId</th>\n      <th>QuestionText</th>\n      <th>QuestionText.1</th>\n      <th>StudentExplanation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>36696</td>\n      <td>31772</td>\n      <td>What fraction of the shape is not shaded? Give...</td>\n      <td>What fraction of the shape is not shaded? Give...</td>\n      <td>I think that 1/3 is the answer, as it's the si...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>36697</td>\n      <td>31772</td>\n      <td>What fraction of the shape is not shaded? Give...</td>\n      <td>What fraction of the shape is not shaded? Give...</td>\n      <td>i think this answer is because 3 triangles are...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/map-charting-student-math-misunderstandings/submission.csv')\nsubmission.head(2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T12:39:43.093016Z","iopub.execute_input":"2025-09-04T12:39:43.093370Z","iopub.status.idle":"2025-09-04T12:39:43.109628Z","shell.execute_reply.started":"2025-09-04T12:39:43.093347Z","shell.execute_reply":"2025-09-04T12:39:43.108583Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"   row_id                             Category Misconception\n0   36696  True_Correct- NA True_Neither- NA False_Neithe...\n1   36697  False_Misconception- Incomplete True_Correct- ...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>Category Misconception</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>36696</td>\n      <td>True_Correct- NA True_Neither- NA False_Neithe...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>36697</td>\n      <td>False_Misconception- Incomplete True_Correct- ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"# Un comment this for fine-tuning binary_model but if you just firstly need to inference on\n# binary_model given to see what it gives on test dataset don't uncomment\n\n\n'''\n# Load CSV\ntrain = pd.read_csv(\"/kaggle/input/map-charting-student-math-misunderstandings/train_Clean.csv\")\n\n# Labels\ntrain[\"binary_label\"] = train[\"Category\"].apply(lambda x: 1 if str(x).split(\"_\")[0].lower() == \"true\" else 0)\n\n# Dataset\ntexts = (\"Question is \" + train[\"QuestionText\"].astype(str) + \"Student answer is \" + train[\"MC_Answer\"].astype(str)).tolist()\nlabels = train[\"binary_label\"].tolist()\ndataset = Dataset.from_dict({\"text\": texts, \"label\": labels})\n\n# Tokenizer\nMODEL_NAME = \"distilbert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\ndataset = dataset.map(lambda x: tokenizer(x[\"text\"], truncation=True, padding=\"max_length\", max_length=128), batched=True)\ndataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n\n# Train/val split\ndataset = dataset.train_test_split(test_size=0.2, seed=42)\n\n# Model\nmodel = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n\n# Training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./binary_model\",\n    num_train_epochs=1,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    weight_decay=0.01,\n    logging_steps=100,\n    save_strategy=\"no\",\n    disable_tqdm=False,\n    report_to=\"none\"  # avoids trying to log to WandB/other\n)\n\n# Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=dataset[\"train\"],\n    eval_dataset=dataset[\"test\"],\n    tokenizer=tokenizer,\n)\n\n# Train\ntrainer.train()\n\n# After trainer.train()\nmodel.save_pretrained(\"./binary_model_final\")\ntokenizer.save_pretrained(\"./binary_model_final\")\n\n# Check CUDA\nprint(\"CUDA available:\", torch.cuda.is_available())\nif torch.cuda.is_available():\n    print(\"Device:\", torch.cuda.current_device(), torch.cuda.get_device_name(0))\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T12:39:43.114875Z","iopub.execute_input":"2025-09-04T12:39:43.117596Z","iopub.status.idle":"2025-09-04T12:39:43.126479Z","shell.execute_reply.started":"2025-09-04T12:39:43.117539Z","shell.execute_reply":"2025-09-04T12:39:43.125675Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"'\\n# Load CSV\\ntrain = pd.read_csv(\"/kaggle/input/map-charting-student-math-misunderstandings/train_Clean.csv\")\\n\\n# Labels\\ntrain[\"binary_label\"] = train[\"Category\"].apply(lambda x: 1 if str(x).split(\"_\")[0].lower() == \"true\" else 0)\\n\\n# Dataset\\ntexts = (\"Question is \" + train[\"QuestionText\"].astype(str) + \"Student answer is \" + train[\"MC_Answer\"].astype(str)).tolist()\\nlabels = train[\"binary_label\"].tolist()\\ndataset = Dataset.from_dict({\"text\": texts, \"label\": labels})\\n\\n# Tokenizer\\nMODEL_NAME = \"distilbert-base-uncased\"\\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\\ndataset = dataset.map(lambda x: tokenizer(x[\"text\"], truncation=True, padding=\"max_length\", max_length=128), batched=True)\\ndataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\\n\\n# Train/val split\\ndataset = dataset.train_test_split(test_size=0.2, seed=42)\\n\\n# Model\\nmodel = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\\n\\n# Training arguments\\ntraining_args = TrainingArguments(\\n    output_dir=\"./binary_model\",\\n    num_train_epochs=1,\\n    per_device_train_batch_size=8,\\n    per_device_eval_batch_size=8,\\n    weight_decay=0.01,\\n    logging_steps=100,\\n    save_strategy=\"no\",\\n    disable_tqdm=False,\\n    report_to=\"none\"  # avoids trying to log to WandB/other\\n)\\n\\n# Trainer\\ntrainer = Trainer(\\n    model=model,\\n    args=training_args,\\n    train_dataset=dataset[\"train\"],\\n    eval_dataset=dataset[\"test\"],\\n    tokenizer=tokenizer,\\n)\\n\\n# Train\\ntrainer.train()\\n\\n# After trainer.train()\\nmodel.save_pretrained(\"./binary_model_final\")\\ntokenizer.save_pretrained(\"./binary_model_final\")\\n\\n# Check CUDA\\nprint(\"CUDA available:\", torch.cuda.is_available())\\nif torch.cuda.is_available():\\n    print(\"Device:\", torch.cuda.current_device(), torch.cuda.get_device_name(0))\\n'"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"# here we are performimg inference on the binary_model\n\n# Paths\nMODEL_NAME = \"distilbert-base-uncased\"\nMODEL_DIR = \"/kaggle/input/distilbert-uncased-fine-tuned/pytorch/default/6/binary_model\"  # same as output_dir used in training\nTEST_CSV = \"/kaggle/input/map-charting-student-math-misunderstandings/test.csv\"\n\n# Load test data\ntest_df = pd.read_csv(TEST_CSV)\n\n# Prepare text\ntexts = (\"Question is \" + test_df[\"QuestionText\"].astype(str) + \" Student answer is \" + test_df[\"StudentExplanation\"].astype(str)).tolist()\n\n# Load tokenizer and model\ntokenizer_binary = AutoTokenizer.from_pretrained(MODEL_DIR)\nmodel_binary = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR)\nmodel_binary.eval()\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel_binary.to(device)\nbinary_model = model_binary\n\n# Tokenize\nencodings = tokenizer_binary(texts, truncation=True, padding=\"max_length\", max_length=128, return_tensors=\"pt\")\ninput_ids = encodings[\"input_ids\"].to(device)\nattention_mask = encodings[\"attention_mask\"].to(device)\nimport torch\nfrom tqdm import tqdm\n\nbatch_size = 32  # reduce if still OOM\nbinary_preds = []\n\nbinary_model.eval()\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nbinary_model.to(device)\n\n# Move encodings to CPU temporarily if needed\ninput_ids_all = encodings[\"input_ids\"]\nattention_mask_all = encodings[\"attention_mask\"]\n\nfor i in tqdm(range(0, len(input_ids_all), batch_size)):\n    batch_input_ids = input_ids_all[i:i+batch_size].to(device)\n    batch_attention_mask = attention_mask_all[i:i+batch_size].to(device)\n\n    with torch.no_grad():\n        outputs = binary_model(input_ids=batch_input_ids, attention_mask=batch_attention_mask)\n        batch_preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n        binary_preds.extend(batch_preds)\n\n# Add predictions to dataframe\ntest_df[\"binary_pred\"] = binary_preds\nprint(test_df[[\"QuestionText\", \"StudentExplanation\", \"binary_pred\"]].head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T12:39:43.127470Z","iopub.execute_input":"2025-09-04T12:39:43.127785Z","iopub.status.idle":"2025-09-04T12:39:44.297067Z","shell.execute_reply.started":"2025-09-04T12:39:43.127759Z","shell.execute_reply":"2025-09-04T12:39:44.296389Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00,  4.52it/s]","output_type":"stream"},{"name":"stdout","text":"                                        QuestionText  \\\n0  What fraction of the shape is not shaded? Give...   \n1  What fraction of the shape is not shaded? Give...   \n2                      Which number is the greatest?   \n\n                                  StudentExplanation  binary_pred  \n0  I think that 1/3 is the answer, as it's the si...            0  \n1  i think this answer is because 3 triangles are...            0  \n2     because the 2 makes it higher than the others.            0  \n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"test_df['binary_pred'].nunique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T12:39:44.297777Z","iopub.execute_input":"2025-09-04T12:39:44.298039Z","iopub.status.idle":"2025-09-04T12:39:44.303389Z","shell.execute_reply.started":"2025-09-04T12:39:44.298022Z","shell.execute_reply":"2025-09-04T12:39:44.302758Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"1"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"# once you have performed fine-tuning of the binary model un comment this for \n# creating the dataset for ternary_model if you are also to fine-tune it\n\n'''\ndef ternary_mapper(x):\n    # Take the last part after splitting by \"_\"\n    last_part = str(x).split(\"_\")[-1].lower()\n    \n    if last_part == \"correct\":\n        return 1\n    elif last_part == \"neither\":\n        return 2\n    elif last_part == \"misconception\":\n        return 0\n    else:\n        return -1\n\n# Apply to the column\ntrain[\"ternary_label\"] = train[\"Category\"].apply(ternary_mapper)\n\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T12:39:44.304276Z","iopub.execute_input":"2025-09-04T12:39:44.304715Z","iopub.status.idle":"2025-09-04T12:39:44.320501Z","shell.execute_reply.started":"2025-09-04T12:39:44.304684Z","shell.execute_reply":"2025-09-04T12:39:44.319934Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"'\\ndef ternary_mapper(x):\\n    # Take the last part after splitting by \"_\"\\n    last_part = str(x).split(\"_\")[-1].lower()\\n    \\n    if last_part == \"correct\":\\n        return 1\\n    elif last_part == \"neither\":\\n        return 2\\n    elif last_part == \"misconception\":\\n        return 0\\n    else:\\n        return -1\\n\\n# Apply to the column\\ntrain[\"ternary_label\"] = train[\"Category\"].apply(ternary_mapper)\\n\\n'"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"train.head(3)\n\n# also uncomment this if you are performimg fine tuning else don't (if you are just inferencing don't uncomment)\n# because it might rise some errors\n\n'''\ntrain_valid = train[train[\"ternary_label\"].isin([0,1,2])].copy()\n\ndef make_ternary_dataset(df):\n    # Concatenate MC_Answer + StudentExplanation + binary prediction as string\n    df[\"input_text\"] = \"Question is \" + df[\"QuestionText\"].astype(str) + \"Student answer is \"+df[\"MC_Answer\"].astype(str)+ \"Score is (1=True, 0=False)  \" + df[\"binary_pred\"].astype(str) + \"Student explanation is \" + df[\"StudentExplanation\"].astype(str) \n    texts = df[\"input_text\"].tolist()\n    labels = df[\"ternary_label\"].tolist()\n    return Dataset.from_dict({\"text\": texts, \"label\": labels})\n\nds_ternary = make_ternary_dataset(train_valid)\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T12:39:44.321422Z","iopub.execute_input":"2025-09-04T12:39:44.321956Z","iopub.status.idle":"2025-09-04T12:39:44.340231Z","shell.execute_reply.started":"2025-09-04T12:39:44.321933Z","shell.execute_reply":"2025-09-04T12:39:44.339681Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"'\\ntrain_valid = train[train[\"ternary_label\"].isin([0,1,2])].copy()\\n\\ndef make_ternary_dataset(df):\\n    # Concatenate MC_Answer + StudentExplanation + binary prediction as string\\n    df[\"input_text\"] = \"Question is \" + df[\"QuestionText\"].astype(str) + \"Student answer is \"+df[\"MC_Answer\"].astype(str)+ \"Score is (1=True, 0=False)  \" + df[\"binary_pred\"].astype(str) + \"Student explanation is \" + df[\"StudentExplanation\"].astype(str) \\n    texts = df[\"input_text\"].tolist()\\n    labels = df[\"ternary_label\"].tolist()\\n    return Dataset.from_dict({\"text\": texts, \"label\": labels})\\n\\nds_ternary = make_ternary_dataset(train_valid)\\n'"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"# uncomment this if you are fine-tuning ternary_model to see if there are unusual labels \n# for the model (if it gives an error youo know that there are unusual labels not in the list)\n# make sure that you run the previuos fine-tuning codes correctly\n\n'''\n\nassert all(l in [0,1,2] for l in ds_ternary[\"label\"]), \"Invalid labels detected!\"\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T12:39:44.340963Z","iopub.execute_input":"2025-09-04T12:39:44.341232Z","iopub.status.idle":"2025-09-04T12:39:44.356310Z","shell.execute_reply.started":"2025-09-04T12:39:44.341208Z","shell.execute_reply":"2025-09-04T12:39:44.355761Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"'\\n\\nassert all(l in [0,1,2] for l in ds_ternary[\"label\"]), \"Invalid labels detected!\"\\n'"},"metadata":{}}],"execution_count":17},{"cell_type":"markdown","source":"we will need to train it on more epochs","metadata":{}},{"cell_type":"code","source":"# uncomment this if you are going to perform fine-tuning on the ternary_model\n\n'''\n\n# Tokenize\ndef tokenize_function(examples):\n    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n\nds_ternary = ds_ternary.map(tokenize_function, batched=True)\nds_ternary.set_format(\"torch\")\nds_ternary = ds_ternary.train_test_split(test_size=0.2, seed=42)\n\n# ----------------------------\n# 6️⃣ Train ternary model\n# ----------------------------\nmodel = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=3)\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\noutput_dir = \"./ternary_model\"\n\ntraining_args = TrainingArguments(\n    output_dir=\"./ternary_model\",\n    do_eval=True,\n    per_device_train_batch_size=16,  # reduce if OOM occurs\n    per_device_eval_batch_size=16,\n    num_train_epochs=1,\n    weight_decay=0.01,\n    logging_steps=100,\n    save_strategy=\"no\",\n    disable_tqdm=False,\n    report_to=\"none\"\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=ds_ternary['train'],\n    eval_dataset=ds_ternary['test'],  # ideally use a real validation split\n    tokenizer=tokenizer\n)\n\ntrainer.train()\n\n    # Save model + tokenizer\nmodel.save_pretrained(\"./ternary_model_final\")\ntokenizer.save_pretrained(\"./ternary_model_final\")\n    \n# ----------------------------\n# 9️⃣ Confirm CUDA\n# ----------------------------\nprint(\"CUDA available:\", torch.cuda.is_available())\nif torch.cuda.is_available():\n    print(\"Device:\", torch.cuda.current_device(), torch.cuda.get_device_name(0))\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T12:39:44.357007Z","iopub.execute_input":"2025-09-04T12:39:44.357353Z","iopub.status.idle":"2025-09-04T12:39:44.372500Z","shell.execute_reply.started":"2025-09-04T12:39:44.357330Z","shell.execute_reply":"2025-09-04T12:39:44.371957Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"'\\n\\n# Tokenize\\ndef tokenize_function(examples):\\n    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\\n\\nds_ternary = ds_ternary.map(tokenize_function, batched=True)\\nds_ternary.set_format(\"torch\")\\nds_ternary = ds_ternary.train_test_split(test_size=0.2, seed=42)\\n\\n# ----------------------------\\n# 6️⃣ Train ternary model\\n# ----------------------------\\nmodel = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=3)\\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\\noutput_dir = \"./ternary_model\"\\n\\ntraining_args = TrainingArguments(\\n    output_dir=\"./ternary_model\",\\n    do_eval=True,\\n    per_device_train_batch_size=16,  # reduce if OOM occurs\\n    per_device_eval_batch_size=16,\\n    num_train_epochs=1,\\n    weight_decay=0.01,\\n    logging_steps=100,\\n    save_strategy=\"no\",\\n    disable_tqdm=False,\\n    report_to=\"none\"\\n)\\n\\ntrainer = Trainer(\\n    model=model,\\n    args=training_args,\\n    train_dataset=ds_ternary[\\'train\\'],\\n    eval_dataset=ds_ternary[\\'test\\'],  # ideally use a real validation split\\n    tokenizer=tokenizer\\n)\\n\\ntrainer.train()\\n\\n    # Save model + tokenizer\\nmodel.save_pretrained(\"./ternary_model_final\")\\ntokenizer.save_pretrained(\"./ternary_model_final\")\\n    \\n# ----------------------------\\n# 9️⃣ Confirm CUDA\\n# ----------------------------\\nprint(\"CUDA available:\", torch.cuda.is_available())\\nif torch.cuda.is_available():\\n    print(\"Device:\", torch.cuda.current_device(), torch.cuda.get_device_name(0))\\n'"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"# here we are just inferencing a ternary_model on test datset in the Distilbert-uncased-fine\n# -tuned models\n\n# Paths\nMODEL_NAME = \"distilbert-base-uncased\"\nMODEL_DIR = \"/kaggle/input/distilbert-uncased-fine-tuned/pytorch/default/6/ternary_model\"  # same as output_dir used in training\nTEST_CSV = \"/kaggle/input/map-charting-student-math-misunderstandings/test.csv\"\n\n# Load test data\n # will be changed to test csv for submission\n\n# Prepare text\ntexts = (\"Student explanation is \" + test_df[\"StudentExplanation\"].astype(str) + \" Score is (1=true, 0=false) \" + test_df[\"binary_pred\"].astype(str)).tolist()\n\n# Load tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\nmodel = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR)\nmodel.eval()\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Tokenize\nencodings = tokenizer(texts, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\ninput_ids = encodings[\"input_ids\"].to(device)\nattention_mask = encodings[\"attention_mask\"].to(device)\nimport torch\nfrom tqdm import tqdm\n\nbatch_size = 32  # reduce if still OOM\nternary_preds = []\n\nmodel.eval()\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Move encodings to CPU temporarily if needed\ninput_ids_all = encodings[\"input_ids\"]\nattention_mask_all = encodings[\"attention_mask\"]\n\nfor i in tqdm(range(0, len(input_ids_all), batch_size)):\n    batch_input_ids = input_ids_all[i:i+batch_size].to(device)\n    batch_attention_mask = attention_mask_all[i:i+batch_size].to(device)\n\n    with torch.no_grad():\n        outputs = model(input_ids=batch_input_ids, attention_mask=batch_attention_mask)\n        batch_preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n        ternary_preds.extend(batch_preds)\n\n# Add predictions to dataframe\ntest_df[\"ternary_pred\"] = ternary_preds\nprint(test_df[[\"StudentExplanation\", \"binary_pred\", \"ternary_pred\"]].head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T12:39:44.373219Z","iopub.execute_input":"2025-09-04T12:39:44.373593Z","iopub.status.idle":"2025-09-04T12:39:44.643433Z","shell.execute_reply.started":"2025-09-04T12:39:44.373566Z","shell.execute_reply":"2025-09-04T12:39:44.642535Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00, 15.10it/s]","output_type":"stream"},{"name":"stdout","text":"                                  StudentExplanation  binary_pred  \\\n0  I think that 1/3 is the answer, as it's the si...            0   \n1  i think this answer is because 3 triangles are...            0   \n2     because the 2 makes it higher than the others.            0   \n\n   ternary_pred  \n0             2  \n1             2  \n2             2  \n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"test_df.head(30)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T12:39:44.644396Z","iopub.execute_input":"2025-09-04T12:39:44.644736Z","iopub.status.idle":"2025-09-04T12:39:44.652843Z","shell.execute_reply.started":"2025-09-04T12:39:44.644706Z","shell.execute_reply":"2025-09-04T12:39:44.652251Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"   row_id  QuestionId                                       QuestionText  \\\n0   36696       31772  What fraction of the shape is not shaded? Give...   \n1   36697       31772  What fraction of the shape is not shaded? Give...   \n2   36698       32835                      Which number is the greatest?   \n\n                                      QuestionText.1  \\\n0  What fraction of the shape is not shaded? Give...   \n1  What fraction of the shape is not shaded? Give...   \n2                      Which number is the greatest?   \n\n                                  StudentExplanation  binary_pred  \\\n0  I think that 1/3 is the answer, as it's the si...            0   \n1  i think this answer is because 3 triangles are...            0   \n2     because the 2 makes it higher than the others.            0   \n\n   ternary_pred  \n0             2  \n1             2  \n2             2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>QuestionId</th>\n      <th>QuestionText</th>\n      <th>QuestionText.1</th>\n      <th>StudentExplanation</th>\n      <th>binary_pred</th>\n      <th>ternary_pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>36696</td>\n      <td>31772</td>\n      <td>What fraction of the shape is not shaded? Give...</td>\n      <td>What fraction of the shape is not shaded? Give...</td>\n      <td>I think that 1/3 is the answer, as it's the si...</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>36697</td>\n      <td>31772</td>\n      <td>What fraction of the shape is not shaded? Give...</td>\n      <td>What fraction of the shape is not shaded? Give...</td>\n      <td>i think this answer is because 3 triangles are...</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>36698</td>\n      <td>32835</td>\n      <td>Which number is the greatest?</td>\n      <td>Which number is the greatest?</td>\n      <td>because the 2 makes it higher than the others.</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"# uncomment this if you are going to perform fine-tuning on the misconception_model\n# else live it commented\n\n'''\n\ntrain['Misconception'] = train['Misconception'].replace('nan', np.nan)\n\n# Get all unique values, including NaN\nunique_values = train['Misconception'].unique()\n\n# Create a mapping: NaN -> 0, others -> 1, 2, ...\nlabel_map = {}\nlabel_index = 1  # start from 1 because we want NaN to be 0\nfor val in unique_values:\n    if pd.isna(val):\n        label_map[val] = 0\n    else:\n        label_map[val] = label_index\n        label_index += 1\n\n# Apply mapping to create new label column\ntrain['Misconception_label'] = train['Misconception'].map(label_map)\n\n# Optional: check the mapping\nprint(label_map)\nprint(train[['Misconception', 'Misconception_label']].head())\n\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T12:39:44.653656Z","iopub.execute_input":"2025-09-04T12:39:44.654014Z","iopub.status.idle":"2025-09-04T12:39:44.673596Z","shell.execute_reply.started":"2025-09-04T12:39:44.653982Z","shell.execute_reply":"2025-09-04T12:39:44.672734Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"\"\\n\\ntrain['Misconception'] = train['Misconception'].replace('nan', np.nan)\\n\\n# Get all unique values, including NaN\\nunique_values = train['Misconception'].unique()\\n\\n# Create a mapping: NaN -> 0, others -> 1, 2, ...\\nlabel_map = {}\\nlabel_index = 1  # start from 1 because we want NaN to be 0\\nfor val in unique_values:\\n    if pd.isna(val):\\n        label_map[val] = 0\\n    else:\\n        label_map[val] = label_index\\n        label_index += 1\\n\\n# Apply mapping to create new label column\\ntrain['Misconception_label'] = train['Misconception'].map(label_map)\\n\\n# Optional: check the mapping\\nprint(label_map)\\nprint(train[['Misconception', 'Misconception_label']].head())\\n\\n\""},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"# uncomment this code to perform fine-tuning of misconception_model on the training dataset\n# if you just need inference on the given model don't uncomment this codes\n\n'''\n\ndef make_misconception_dataset(df):\n    # Concatenate MC_Answer + StudentExplanation + binary prediction as string\n    df[\"input_text\"] = \"Question is \" + df[\"QuestionText\"].astype(str) + \"Student answer is \"+df[\"MC_Answer\"].astype(str)+ \"Score is (1=True, 0=False)  \" + df[\"binary_pred\"].astype(str) + \"Student explanation is \" + df[\"StudentExplanation\"].astype(str) + \"CATEGORY IS <VERY IMPORTANT> \" + df['ternary_pred'].astype(str) +\" </VERY IMPORTANT>\"\n    texts = df[\"input_text\"].tolist()\n    labels = df[\"Misconception_label\"].tolist()\n    return Dataset.from_dict({\"text\": texts, \"label\": labels})\n\nds_misconception_ = make_misconception_dataset(train)\n\n\n# Tokenize\ndef tokenize_function(examples):\n    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n\nds_misconception_ = ds_misconception_.map(tokenize_function, batched=True)\nds_misconception_.set_format(\"torch\")\nds_misconception = ds_misconception_.train_test_split(test_size=0.2, seed=42)\n\n# ----------------------------\n# 6️⃣ Train ternary model\n# ----------------------------\nmodel = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=36)\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\noutput_dir = \"./misconception_model\"\n\ntraining_args = TrainingArguments(\n    output_dir=\"./misconception_model\",\n    do_eval=True,\n    per_device_train_batch_size=16,  # reduce if OOM occurs\n    per_device_eval_batch_size=16,\n    num_train_epochs=1,\n    weight_decay=0.01,\n    logging_steps=100,\n    save_strategy=\"no\",\n    disable_tqdm=False,\n    report_to=\"none\"\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=ds_misconception['train'],\n    eval_dataset=ds_misconception['test'],  # ideally use a real validation split\n    tokenizer=tokenizer\n)\n\ntrainer.train()\n\n    # Save model + tokenizer\nmodel.save_pretrained(\"./misconception_model_final\")\ntokenizer.save_pretrained(\"./misconception_model_final\")\n    \n# ----------------------------\n# 9️⃣ Confirm CUDA\n# ----------------------------\nprint(\"CUDA available:\", torch.cuda.is_available())\nif torch.cuda.is_available():\n    print(\"Device:\", torch.cuda.current_device(), torch.cuda.get_device_name(0))\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T12:39:44.674591Z","iopub.execute_input":"2025-09-04T12:39:44.675020Z","iopub.status.idle":"2025-09-04T12:39:44.696372Z","shell.execute_reply.started":"2025-09-04T12:39:44.674998Z","shell.execute_reply":"2025-09-04T12:39:44.695691Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"'\\n\\ndef make_misconception_dataset(df):\\n    # Concatenate MC_Answer + StudentExplanation + binary prediction as string\\n    df[\"input_text\"] = \"Question is \" + df[\"QuestionText\"].astype(str) + \"Student answer is \"+df[\"MC_Answer\"].astype(str)+ \"Score is (1=True, 0=False)  \" + df[\"binary_pred\"].astype(str) + \"Student explanation is \" + df[\"StudentExplanation\"].astype(str) + \"CATEGORY IS <VERY IMPORTANT> \" + df[\\'ternary_pred\\'].astype(str) +\" </VERY IMPORTANT>\"\\n    texts = df[\"input_text\"].tolist()\\n    labels = df[\"Misconception_label\"].tolist()\\n    return Dataset.from_dict({\"text\": texts, \"label\": labels})\\n\\nds_misconception_ = make_misconception_dataset(train)\\n\\n\\n# Tokenize\\ndef tokenize_function(examples):\\n    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\\n\\nds_misconception_ = ds_misconception_.map(tokenize_function, batched=True)\\nds_misconception_.set_format(\"torch\")\\nds_misconception = ds_misconception_.train_test_split(test_size=0.2, seed=42)\\n\\n# ----------------------------\\n# 6️⃣ Train ternary model\\n# ----------------------------\\nmodel = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=36)\\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\\noutput_dir = \"./misconception_model\"\\n\\ntraining_args = TrainingArguments(\\n    output_dir=\"./misconception_model\",\\n    do_eval=True,\\n    per_device_train_batch_size=16,  # reduce if OOM occurs\\n    per_device_eval_batch_size=16,\\n    num_train_epochs=1,\\n    weight_decay=0.01,\\n    logging_steps=100,\\n    save_strategy=\"no\",\\n    disable_tqdm=False,\\n    report_to=\"none\"\\n)\\n\\ntrainer = Trainer(\\n    model=model,\\n    args=training_args,\\n    train_dataset=ds_misconception[\\'train\\'],\\n    eval_dataset=ds_misconception[\\'test\\'],  # ideally use a real validation split\\n    tokenizer=tokenizer\\n)\\n\\ntrainer.train()\\n\\n    # Save model + tokenizer\\nmodel.save_pretrained(\"./misconception_model_final\")\\ntokenizer.save_pretrained(\"./misconception_model_final\")\\n    \\n# ----------------------------\\n# 9️⃣ Confirm CUDA\\n# ----------------------------\\nprint(\"CUDA available:\", torch.cuda.is_available())\\nif torch.cuda.is_available():\\n    print(\"Device:\", torch.cuda.current_device(), torch.cuda.get_device_name(0))\\n'"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"print(model.config.num_labels)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T12:39:44.697124Z","iopub.execute_input":"2025-09-04T12:39:44.697380Z","iopub.status.idle":"2025-09-04T12:39:44.716291Z","shell.execute_reply.started":"2025-09-04T12:39:44.697353Z","shell.execute_reply":"2025-09-04T12:39:44.715456Z"}},"outputs":[{"name":"stdout","text":"3\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"\n# Paths\nMODEL_NAME = \"distilbert-base-uncased\"\nMODEL_DIR = \"/kaggle/input/distilbert-uncased-fine-tuned/pytorch/default/6/misconception_model\"  # same as output_dir used in training\nTEST_CSV = \"/kaggle/input/map-charting-student-math-misunderstandings/test.csv\"\n\n# Load test data\ntest_df  # will be changed to test csv for submission\n\n# Prepare text\ntexts = (\"Question is \" + test_df[\"QuestionText\"].astype(str) + \"Score is (1=True, 0=False)  \" + test_df[\"binary_pred\"].astype(str) + \"Student explanation is \" + test_df[\"StudentExplanation\"].astype(str) + \"CATEGORY IS <VERY IMPORTANT> \" + test_df['ternary_pred'].astype(str) +\" </VERY IMPORTANT> if very important is not 0 predict/ 0\").tolist()\n\n# Load tokenizer and model\n\nmodel.eval()\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Tokenize\nencodings = tokenizer(texts, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\ninput_ids = encodings[\"input_ids\"].to(device)\nattention_mask = encodings[\"attention_mask\"].to(device)\nimport torch\nfrom tqdm import tqdm\n\nbatch_size = 32  # reduce if still OOM\nmisconception_preds = []\n\nmodel.eval()\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Move encodings to CPU temporarily if needed\ninput_ids_all = encodings[\"input_ids\"]\nattention_mask_all = encodings[\"attention_mask\"]\n\nfor i in tqdm(range(0, len(input_ids_all), batch_size)):\n    batch_input_ids = input_ids_all[i:i+batch_size].to(device)\n    batch_attention_mask = attention_mask_all[i:i+batch_size].to(device)\n\n    with torch.no_grad():\n        outputs = model(input_ids=batch_input_ids, attention_mask=batch_attention_mask)\n        batch_preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n        misconception_preds.extend(batch_preds)\n\n# Add predictions to dataframe\ntest_df[\"misconception_pred\"] = misconception_preds\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T12:39:44.717075Z","iopub.execute_input":"2025-09-04T12:39:44.717433Z","iopub.status.idle":"2025-09-04T12:39:44.812366Z","shell.execute_reply.started":"2025-09-04T12:39:44.717409Z","shell.execute_reply":"2025-09-04T12:39:44.811428Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00, 15.50it/s]\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"test_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T12:39:44.813331Z","iopub.execute_input":"2025-09-04T12:39:44.814160Z","iopub.status.idle":"2025-09-04T12:39:44.824017Z","shell.execute_reply.started":"2025-09-04T12:39:44.814134Z","shell.execute_reply":"2025-09-04T12:39:44.823281Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"   row_id  QuestionId                                       QuestionText  \\\n0   36696       31772  What fraction of the shape is not shaded? Give...   \n1   36697       31772  What fraction of the shape is not shaded? Give...   \n2   36698       32835                      Which number is the greatest?   \n\n                                      QuestionText.1  \\\n0  What fraction of the shape is not shaded? Give...   \n1  What fraction of the shape is not shaded? Give...   \n2                      Which number is the greatest?   \n\n                                  StudentExplanation  binary_pred  \\\n0  I think that 1/3 is the answer, as it's the si...            0   \n1  i think this answer is because 3 triangles are...            0   \n2     because the 2 makes it higher than the others.            0   \n\n   ternary_pred  misconception_pred  \n0             2                   2  \n1             2                   0  \n2             2                   0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>QuestionId</th>\n      <th>QuestionText</th>\n      <th>QuestionText.1</th>\n      <th>StudentExplanation</th>\n      <th>binary_pred</th>\n      <th>ternary_pred</th>\n      <th>misconception_pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>36696</td>\n      <td>31772</td>\n      <td>What fraction of the shape is not shaded? Give...</td>\n      <td>What fraction of the shape is not shaded? Give...</td>\n      <td>I think that 1/3 is the answer, as it's the si...</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>36697</td>\n      <td>31772</td>\n      <td>What fraction of the shape is not shaded? Give...</td>\n      <td>What fraction of the shape is not shaded? Give...</td>\n      <td>i think this answer is because 3 triangles are...</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>36698</td>\n      <td>32835</td>\n      <td>Which number is the greatest?</td>\n      <td>Which number is the greatest?</td>\n      <td>because the 2 makes it higher than the others.</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"MODEL_DIR = \"/kaggle/input/distilbert-uncased-fine-tuned/pytorch/default/6/misconception_model\"  # same as output_dir used in training\ntokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\nmodel = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR)\nprint(model.config.num_labels)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T12:39:44.824931Z","iopub.execute_input":"2025-09-04T12:39:44.825301Z","iopub.status.idle":"2025-09-04T12:39:44.929990Z","shell.execute_reply.started":"2025-09-04T12:39:44.825270Z","shell.execute_reply":"2025-09-04T12:39:44.929212Z"}},"outputs":[{"name":"stdout","text":"36\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"import pandas as pd\n\n# Load your CSV\ndf = test_df # replace with your path\n\n# 1️⃣ Create decoding dictionaries\nbinary_map = {0: \"False\", 1: \"True\"}\nternary_map = {0: \"Misconception\", 1: \"Correct\", 2: \"Neither\"}\nmisconception_map = {0: \"NA\", 1: \"scale\", 2: \"incomplete\"}\n\n# 2️⃣ Decode columns\ndf[\"binary_decoded\"] = df[\"binary_pred\"].map(binary_map)\ndf[\"ternary_decoded\"] = df[\"ternary_pred\"].map(ternary_map)\ndf[\"misconception_decoded\"] = df[\"misconception_pred\"].map(misconception_map)\n\n# 3️⃣ Merge into a single feature\ndf[\"CategoryMisconception\"] = (\n    df[\"binary_decoded\"] + \"_\" + df[\"ternary_decoded\"] + \"- \" + df[\"misconception_decoded\"]\n)\n\n# 4️⃣ Keep only relevant columns for clarity\nmerged_df = df[[\"row_id\", \"CategoryMisconception\"]]\n\n# Optional: If you want unique values per QuestionId\n# merged_df = merged_df.groupby(\"QuestionId\")[\"Misconception\"].apply(list).reset_index()\n\nprint(merged_df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T12:39:44.930723Z","iopub.execute_input":"2025-09-04T12:39:44.930968Z","iopub.status.idle":"2025-09-04T12:39:44.944139Z","shell.execute_reply.started":"2025-09-04T12:39:44.930950Z","shell.execute_reply":"2025-09-04T12:39:44.943349Z"}},"outputs":[{"name":"stdout","text":"   row_id      CategoryMisconception\n0   36696  False_Neither- incomplete\n1   36697          False_Neither- NA\n2   36698          False_Neither- NA\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"merged_df.to_csv('submission.csv', index = False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T12:39:44.944986Z","iopub.execute_input":"2025-09-04T12:39:44.945287Z","iopub.status.idle":"2025-09-04T12:39:44.964606Z","shell.execute_reply.started":"2025-09-04T12:39:44.945257Z","shell.execute_reply":"2025-09-04T12:39:44.963832Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"submission = pd.read_csv('/kaggle/working/submission.csv')\nsubmission","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T12:39:44.965434Z","iopub.execute_input":"2025-09-04T12:39:44.965647Z","iopub.status.idle":"2025-09-04T12:39:44.989599Z","shell.execute_reply.started":"2025-09-04T12:39:44.965630Z","shell.execute_reply":"2025-09-04T12:39:44.988576Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"   row_id      CategoryMisconception\n0   36696  False_Neither- incomplete\n1   36697          False_Neither- NA\n2   36698          False_Neither- NA","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>CategoryMisconception</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>36696</td>\n      <td>False_Neither- incomplete</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>36697</td>\n      <td>False_Neither- NA</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>36698</td>\n      <td>False_Neither- NA</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":29},{"cell_type":"markdown","source":"### REMEMBER TO UPVOTE ANY THING","metadata":{}},{"cell_type":"code","source":"# sorry that the codes aren't very clean I didn't get enough time\n\n# Also remember that it is possible to make three prediction per sample separated by space\n\n# in the CategoryMisconception column.\n\n# thank you so much for your kind attention","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}